{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "KafKn6o7mQK6",
   "metadata": {
    "id": "KafKn6o7mQK6"
   },
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6020553",
   "metadata": {
    "id": "f6020553"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-fCRI2JKoRRN",
   "metadata": {
    "id": "-fCRI2JKoRRN"
   },
   "source": [
    "# Importando os dados\n",
    "<br>\n",
    "A base de dados foi escolhido no Kaggle no seguinte link <br>\n",
    "(https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nERRvVBbd2-D",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "nERRvVBbd2-D",
    "outputId": "f3dbe8cf-473f-49d8-9d6e-af057db91065"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pMHiQ831msw9",
   "metadata": {
    "id": "pMHiQ831msw9"
   },
   "source": [
    "## Verificando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oaivOOtmnPe_",
   "metadata": {
    "id": "oaivOOtmnPe_"
   },
   "source": [
    "Verificando se há dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "l3SanhxnnINB",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l3SanhxnnINB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5   \n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321  \\\n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22   \n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838  \\\n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount   \n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \\\n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56GfOl61tvwq",
   "metadata": {
    "id": "56GfOl61tvwq"
   },
   "source": [
    "O dataset foi tratado com um metodo de redução de dimensionalidade e alterou o nome da coluna para proteger os dados dos clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qFOyBd07nJkB",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qFOyBd07nJkB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKqgoYsdnSn9",
   "metadata": {
    "id": "PKqgoYsdnSn9"
   },
   "source": [
    "Aqui estou inspecionando para ver o balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e160f6ba",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "e160f6ba",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uZ8gY_lKnbx6",
   "metadata": {
    "id": "uZ8gY_lKnbx6"
   },
   "source": [
    "Como podemos ver ela é extremamente desbalanceada. É necessário alguma tecnica de imblearn. Alguns metodos são:Gerar dados sinteticos, Oversampling ou undersampling para assim aumentar ou diminuir frequência de uma classe nesse notebook optei por oversampling com geração de dados sinteticos. Eu usei a função SMOTE que gera um oversampling com dados sinteticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f726d58",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9f726d58"
   },
   "outputs": [],
   "source": [
    "ys = df.Class.value_counts().loc[1] / df.Class.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71143b8",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "c71143b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001727485630620034"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oyJuFJKHn7BS",
   "metadata": {
    "id": "oyJuFJKHn7BS"
   },
   "source": [
    "# Preparando os dados para o oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d7f9e8",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "75d7f9e8"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'Class')\n",
    "y = df.Class\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify = df.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jFOODcnpGpN",
   "metadata": {
    "id": "7jFOODcnpGpN"
   },
   "source": [
    "Aqui importo a biblioteca imblearn e busco a função SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53ce84c",
   "metadata": {
    "id": "d53ce84c"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lG47eP4aqDrN",
   "metadata": {
    "id": "lG47eP4aqDrN"
   },
   "source": [
    "A função SMOTE deve ser aplicada apenas na parte de treinamento dos dados para treinar o modelo o que é uma fraude ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cfe592",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a6cfe592"
   },
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81NxVHHqU5W",
   "metadata": {
    "id": "f81NxVHHqU5W"
   },
   "source": [
    "Aqui import o modelo que desejo. Eu usei o RandomForestClassifier ao enves do modelo XGBoostClassifier por um motivo ele é mais simples que o XGBoost e isso gera menos overfit. Como há poucos é possivel que ocorra um underfit ou overfit no XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d918bc",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "c7d918bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8baea9c4",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8baea9c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KkUCEhgwrFSh",
   "metadata": {
    "id": "KkUCEhgwrFSh"
   },
   "source": [
    "Usei o f1_score pois ele é a média harmonica da precisão e recall assim tendo uma noção do balanceamento das métricas. Nesse projeto é mais importante que o recall seja alto para evitar falsos negativos. Quanto maior o recall mais fraudes são detectadas corretamente e menos falsos negativos ocorrem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19579b1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f19579b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8523206751054853"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(X_train_over, y_train_over)\n",
    "pred = modelo.predict(X_val)\n",
    "pred_proba = modelo.predict_proba(X_val)[:,1]\n",
    "f1 = f1_score(y_val, pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d672a4a1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "d672a4a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IeTSq5Xsr2-0",
   "metadata": {
    "id": "IeTSq5Xsr2-0"
   },
   "source": [
    "Aqui podemos ver que o modelo tem um recall de 82,11% o que torna muito superior a baseline de apenas chutar que não há nenhuma fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec65f6a",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8ec65f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.11\n"
     ]
    }
   ],
   "source": [
    "resultado = recall_score(y_val, pred)\n",
    "print(f'{resultado * 100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NTaafH4lsESo",
   "metadata": {
    "id": "NTaafH4lsESo"
   },
   "source": [
    "# ROC e AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "OZYhT0lfHfVm",
   "metadata": {
    "id": "OZYhT0lfHfVm"
   },
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbOSx5rZsL4Z",
   "metadata": {
    "id": "dbOSx5rZsL4Z"
   },
   "source": [
    "Aqui é usado o roc para visualizar qual é a melhor opção para o modelo. Nesse caso Quanto menor os falsos positivos melhor. Um falso positivo irá bloquear uma fraude de ocorrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "204dd4a2",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "204dd4a2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_val, pred_proba)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WI0XIktUsjf0",
   "metadata": {
    "id": "WI0XIktUsjf0"
   },
   "source": [
    "Podemos ver no gráfico que os verdadeiros positivos chegam bem alto quando se inicia um aumento nos falsos positivos. Mas nesse caso é importante minimizar falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18240b66",
   "metadata": {
    "id": "18240b66"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "T7rGISiIMk57",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "T7rGISiIMk57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844326426212812"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbymzahnMtQH",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fbymzahnMtQH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9870034681438278"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_em_tunning = RandomForestClassifier(n_estimators = 300, min_samples_split = 4)\n",
    "modelo_em_tunning.fit(X_train_over, y_train_over)\n",
    "preds = modelo_em_tunning.predict(X_val)\n",
    "pred_proba = modelo_em_tunning.predict_proba(X_val)\n",
    "roc_auc_score(y_val, pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PmXREsfzt-jN",
   "metadata": {
    "id": "PmXREsfzt-jN"
   },
   "source": [
    "Mesmo com um leve ajuste dos hiperparametros não houve um ganho substancial no f1_score. Apenas no AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d7fe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595744680851064"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62a05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211382113821138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ba2bf",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6975f5",
   "metadata": {},
   "source": [
    "Com um método básico de imblearn temos um aumento substancial na nosa baseline. Considerando que ela era chutar que não há fraudes, com essa baseline temos uma precisão de 99,87% de precisão e 0% de recall tendo um f1 score de 0 por ter um recall de 0%. Com um tratamento adequado dos dados tem um ganho alto de f1 score e recall em 84,38% no f1 score e no recall de 81,30%. Com um ajuste de hiperparametros com gridsearch poderia ter resultados bem melhores ou até mesmo usando o XGBoost. Mas optei por simplicidade para não ocorrer overfit nem underfit"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
